{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA Setup"
      ],
      "metadata": {
        "id": "sRQiD7xrkOaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyrvMF1QkN5U",
        "outputId": "4b158a4c-995d-47ab-f277-fff2c7936b4f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov  5 17:55:52 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxVARa4-kaEb",
        "outputId": "148dcec5-f723-4195-f62a-5c526f347216"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzZO0MBskcXI",
        "outputId": "62c65351-341b-4abf-eec0-73cc059e850c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS5RkrU6keFu",
        "outputId": "16236e1c-95fb-4bbd-f5e0-045bc04f0d6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpvc9blf4i\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Find the transpose of the matrix using Shared memory in GPU"
      ],
      "metadata": {
        "id": "e7CiISIb69Wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile qtranpose.cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define TILE_DIM 32\n",
        "\n",
        "__global__ void matrixTransposeShared(float *input, float *output, int width, int height) {\n",
        "    __shared__ float tile[TILE_DIM][TILE_DIM + 1];\n",
        "\n",
        "    int x = blockIdx.x * TILE_DIM + threadIdx.x;\n",
        "    int y = blockIdx.y * TILE_DIM + threadIdx.y;\n",
        "    if (x < width && y < height) {\n",
        "        tile[threadIdx.y][threadIdx.x] = input[y * width + x];\n",
        "    }\n",
        "    __syncthreads();\n",
        "    int transposedX = blockIdx.y * TILE_DIM + threadIdx.x;\n",
        "    int transposedY = blockIdx.x * TILE_DIM + threadIdx.y;\n",
        "\n",
        "    if (transposedX < height && transposedY < width) {\n",
        "        output[transposedY * height + transposedX] = tile[threadIdx.x][threadIdx.y];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int width = 1024;\n",
        "    int height = 1024;\n",
        "    int size = width * height * sizeof(float);\n",
        "\n",
        "    float *h_input = new float[width * height];\n",
        "    float *h_output = new float[width * height];\n",
        "    for (int i = 0; i < width * height; ++i) {\n",
        "        h_input[i] = static_cast<float>(i);\n",
        "    }\n",
        "\n",
        "    float *d_input, *d_output;\n",
        "    cudaMalloc((void**)&d_input, size);\n",
        "    cudaMalloc((void**)&d_output, size);\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 blockSize(TILE_DIM, TILE_DIM);\n",
        "    dim3 gridSize((width + TILE_DIM - 1) / TILE_DIM, (height + TILE_DIM - 1) / TILE_DIM);\n",
        "    matrixTransposeShared<<<gridSize, blockSize>>>(d_input, d_output, width, height);\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, size, cudaMemcpyDeviceToHost);\n",
        "    std::cout << \"Output matrix (transposed): \" << std::endl;\n",
        "    for (int i = 0; i < 5; ++i) {\n",
        "        for (int j = 0; j < 5; ++j) {\n",
        "            std::cout << h_output[i * width + j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    delete[] h_input;\n",
        "    delete[] h_output;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi3l9VY3686Z",
        "outputId": "f4131bee-1e0d-4d73-b100-f5ecba88dfc0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing qtranpose.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc qtranpose.cu -o qtranpose"
      ],
      "metadata": {
        "id": "25tr3LY8692L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./qtranpose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIgztOCU6-Dp",
        "outputId": "e3b2066e-127c-4bf5-a317-6c390db3ee3a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output matrix (transposed): \n",
            "0 1024 2048 3072 4096 \n",
            "1 1025 2049 3073 4097 \n",
            "2 1026 2050 3074 4098 \n",
            "3 1027 2051 3075 4099 \n",
            "4 1028 2052 3076 4100 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write a CUDA C kernel that performs an array's sum using shared memory."
      ],
      "metadata": {
        "id": "6R8kGz1Cj-S5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile qarraysum.cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "__global__ void arraySumShared(int *arr, int *result, int n) {\n",
        "    extern __shared__ int sharedData[];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sharedData[tid] = (index < n) ? arr[index] : 0;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride /= 2) {\n",
        "        if (tid < stride) {\n",
        "            sharedData[tid] += sharedData[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) {\n",
        "        atomicAdd(result, sharedData[0]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1024;\n",
        "    int *h_arr = new int[n];\n",
        "    int *h_result = new int;\n",
        "    *h_result = 0;\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        h_arr[i] = 1;\n",
        "    }\n",
        "\n",
        "    int *d_arr, *d_result;\n",
        "    cudaMalloc((void**)&d_arr, n * sizeof(int));\n",
        "    cudaMalloc((void**)&d_result, sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_arr, h_arr, n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_result, h_result, sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (n + blockSize - 1) / blockSize;\n",
        "    arraySumShared<<<gridSize, blockSize, blockSize * sizeof(int)>>>(d_arr, d_result, n);\n",
        "\n",
        "    cudaMemcpy(h_result, d_result, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    std::cout << \"Sum of array: \" << *h_result << std::endl;\n",
        "\n",
        "\n",
        "    cudaFree(d_arr);\n",
        "    cudaFree(d_result);\n",
        "    delete[] h_arr;\n",
        "    delete h_result;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "FuHKZ85Hz32L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffaf18d3-1b25-43bc-da95-8445f113ea7e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing qarraysum.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc qarraysum.cu -o qarraysum"
      ],
      "metadata": {
        "id": "EsTYhfWV0uEC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./qarraysum"
      ],
      "metadata": {
        "id": "xr6R3aeU0zVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad504887-9bc6-47e8-eb0d-235e29281d8d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of array: 1024\n"
          ]
        }
      ]
    }
  ]
}
