{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA Setup"
      ],
      "metadata": {
        "id": "sRQiD7xrkOaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyrvMF1QkN5U",
        "outputId": "c7292c3e-f77f-4b45-ed95-e89f59890299"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov  5 05:56:20 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxVARa4-kaEb",
        "outputId": "9fc4f8db-ef0d-49a5-f203-a0ba57c0e511"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzZO0MBskcXI",
        "outputId": "5004488f-4c49-48d8-a44a-d6c213fa9bfa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS5RkrU6keFu",
        "outputId": "66a84ef8-c1cb-4211-aa48-cd4dc387d104"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp2n6tgnvs\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kernal I Configuration\n",
        "\n",
        "## Find the transpose of the matrix using Shared memory in GPU"
      ],
      "metadata": {
        "id": "6R8kGz1Cj-S5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile qtranpose.cu\n",
        "#include <stdio.h>\n",
        "#include <ctime>\n",
        "\n",
        "#define N 1024\n",
        "#define DIM 32\n",
        "\n",
        "__global__ void transpose(int *org, int *trans) {\n",
        "    __shared__ int shared[DIM][DIM];\n",
        "    int x = blockIdx.x * DIM + threadIdx.x;\n",
        "    int y = blockIdx.y * DIM + threadIdx.y;\n",
        "    if (x < N && y < N) {\n",
        "        shared[threadIdx.y][threadIdx.x] = org[y * N + x];\n",
        "    }\n",
        "    __syncthreads();\n",
        "    if (x < N && y < N) {\n",
        "        trans[x * N + y] = shared[threadIdx.x][threadIdx.y];\n",
        "    }\n",
        "}\n",
        "\n",
        "void transposeCPU(int *org, int *trans) {\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            trans[j * N + i] = org[i * N + j];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int *h_org, *h_trans;\n",
        "    int *d_org, *d_trans;\n",
        "\n",
        "    h_org = (int*)malloc(N * N * sizeof(int));\n",
        "    h_trans = (int*)malloc(N * N * sizeof(int));\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            h_org[i * N + j] = i * N + j;\n",
        "        }\n",
        "    }\n",
        "    cudaMalloc((void**)&d_org, N * N * sizeof(int));\n",
        "    cudaMalloc((void**)&d_trans, N * N * sizeof(int));\n",
        "    cudaMemcpy(d_org, h_org, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    int block_size = 32;\n",
        "    dim3 blockDim(block_size, block_size);\n",
        "    dim3 gridDim((N + block_size - 1) / block_size, (N + block_size - 1) / block_size);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "\n",
        "    transpose<<<gridDim, blockDim>>>(d_org, d_trans);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    printf(\"CUDA Time for N=%d, Threads=%d: %.2f ms\\n\", N, block_size * block_size, milliseconds);\n",
        "\n",
        "\n",
        "    cudaMemcpy(h_trans, d_trans, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "    cudaFree(d_org);\n",
        "    cudaFree(d_trans);\n",
        "\n",
        "\n",
        "    clock_t cpu_start = clock();\n",
        "    transposeCPU(h_org, h_trans);\n",
        "    clock_t cpu_end = clock();\n",
        "    double cpu_time = ((double)(cpu_end - cpu_start)) / CLOCKS_PER_SEC * 1000.0;\n",
        "    printf(\"CPU Time for N=%d: %.2f ms\\n\", N, cpu_time);\n",
        "\n",
        "\n",
        "    printf(\"Original Matrix (5x5 subset):\\n\");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        for (int j = 0; j < 5; j++) {\n",
        "            printf(\"%d \", h_org[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"\\nTransposed Matrix (5x5 subset):\\n\");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        for (int j = 0; j < 5; j++) {\n",
        "            printf(\"%d \", h_trans[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "\n",
        "    free(h_org);\n",
        "    free(h_trans);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "FuHKZ85Hz32L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe278de6-78a4-4e61-a09e-b6735b2b7e57"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing qtranpose.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc qtranpose.cu -o qtranpose"
      ],
      "metadata": {
        "id": "EsTYhfWV0uEC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./qtranpose"
      ],
      "metadata": {
        "id": "xr6R3aeU0zVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb5611f-d07e-41da-ec7a-b8acdb666a1d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Time for N=1024, Threads=1024: 134.83 ms\n",
            "CPU Time for N=1024: 19.57 ms\n",
            "Original Matrix (5x5 subset):\n",
            "0 1 2 3 4 \n",
            "1024 1025 1026 1027 1028 \n",
            "2048 2049 2050 2051 2052 \n",
            "3072 3073 3074 3075 3076 \n",
            "4096 4097 4098 4099 4100 \n",
            "\n",
            "Transposed Matrix (5x5 subset):\n",
            "0 1024 2048 3072 4096 \n",
            "1 1025 2049 3073 4097 \n",
            "2 1026 2050 3074 4098 \n",
            "3 1027 2051 3075 4099 \n",
            "4 1028 2052 3076 4100 \n"
          ]
        }
      ]
    }
  ]
}