{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA Setup"
      ],
      "metadata": {
        "id": "sRQiD7xrkOaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyrvMF1QkN5U",
        "outputId": "c7292c3e-f77f-4b45-ed95-e89f59890299"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov  5 05:56:20 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxVARa4-kaEb",
        "outputId": "9fc4f8db-ef0d-49a5-f203-a0ba57c0e511"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzZO0MBskcXI",
        "outputId": "5004488f-4c49-48d8-a44a-d6c213fa9bfa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS5RkrU6keFu",
        "outputId": "66a84ef8-c1cb-4211-aa48-cd4dc387d104"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp2n6tgnvs\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kernal II Configuration\n",
        "\n",
        "## erform matrix-matrix multiplication using shared memory"
      ],
      "metadata": {
        "id": "6R8kGz1Cj-S5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile qconvolution.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void convolve1D(float *input, float *output, float *kernel, int inputSize, int kernelSize) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int halfKernel = kernelSize / 2;\n",
        "    if (idx >= inputSize) return;\n",
        "\n",
        "    float sum = 0;\n",
        "    for (int j = -halfKernel; j <= halfKernel; ++j) {\n",
        "        int index = idx + j;\n",
        "        if (index >= 0 && index < inputSize)\n",
        "            sum += input[index] * kernel[halfKernel + j];\n",
        "    }\n",
        "    output[idx] = sum;\n",
        "}\n",
        "\n",
        "void testConfiguration(int N, int threads, int kernelSize) {\n",
        "    printf(\"Running with N = %d, Threads per block = %d\\n\", N, threads);\n",
        "\n",
        "    float *h_input = (float*)malloc(N * sizeof(float));\n",
        "    float *h_output = (float*)malloc(N * sizeof(float));\n",
        "    float h_kernel[] = {0.2, 0.2, 0.2, 0.2, 0.2};\n",
        "\n",
        "    for (int i = 0; i < N; ++i) h_input[i] = 1.0f;\n",
        "\n",
        "    float *d_input, *d_output, *d_kernel;\n",
        "    cudaMalloc(&d_input, N * sizeof(float));\n",
        "    cudaMalloc(&d_output, N * sizeof(float));\n",
        "    cudaMalloc(&d_kernel, kernelSize * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_kernel, h_kernel, kernelSize * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int numBlocks = (N + threads - 1) / threads;\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    convolve1D<<<numBlocks, threads>>>(d_input, d_output, d_kernel, N, kernelSize);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    printf(\"Time taken for N = %d, Threads = %d: %f ms\\n\", N, threads, milliseconds);\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    cudaFree(d_kernel);\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int kernelSize = 5;\n",
        "    int Ns[] = {1024, 2048, 8192}; // Different input sizes\n",
        "    int threads[] = {512, 1024, 2048}; // Different thread configurations\n",
        "\n",
        "    for (int i = 0; i < 3; ++i) {\n",
        "        for (int j = 0; j < 3; ++j) {\n",
        "            testConfiguration(Ns[i], threads[j], kernelSize);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "FuHKZ85Hz32L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc11a714-2b6a-4b22-e17b-64c4382e450d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing qconvolution.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc qconvolution.cu -o qconvolution"
      ],
      "metadata": {
        "id": "EsTYhfWV0uEC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./qconvolution"
      ],
      "metadata": {
        "id": "xr6R3aeU0zVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da89e6f-f76d-4d13-9325-97c2ff2849a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running with N = 1024, Threads per block = 512\n",
            "Time taken for N = 1024, Threads = 512: 42.205185 ms\n",
            "Running with N = 1024, Threads per block = 1024\n",
            "Time taken for N = 1024, Threads = 1024: 0.018240 ms\n",
            "Running with N = 1024, Threads per block = 2048\n",
            "Time taken for N = 1024, Threads = 2048: 0.023072 ms\n",
            "Running with N = 2048, Threads per block = 512\n",
            "Time taken for N = 2048, Threads = 512: 0.016128 ms\n",
            "Running with N = 2048, Threads per block = 1024\n",
            "Time taken for N = 2048, Threads = 1024: 0.016384 ms\n",
            "Running with N = 2048, Threads per block = 2048\n",
            "Time taken for N = 2048, Threads = 2048: 0.009920 ms\n",
            "Running with N = 8192, Threads per block = 512\n",
            "Time taken for N = 8192, Threads = 512: 0.016576 ms\n",
            "Running with N = 8192, Threads per block = 1024\n",
            "Time taken for N = 8192, Threads = 1024: 0.017376 ms\n",
            "Running with N = 8192, Threads per block = 2048\n",
            "Time taken for N = 8192, Threads = 2048: 0.008160 ms\n"
          ]
        }
      ]
    }
  ]
}