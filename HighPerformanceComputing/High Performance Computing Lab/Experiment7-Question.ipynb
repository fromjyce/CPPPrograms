{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to CUDA programming\n"
      ],
      "metadata": {
        "id": "0V8NnvmSKrFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the cuda compiler version"
      ],
      "metadata": {
        "id": "ZVw_J3CaK1SI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "nCyDEZzFQHam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9YjE75qKWqE"
      },
      "outputs": [],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples.git"
      ],
      "metadata": {
        "id": "fLAbQkLUPkEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd cuda-samples/Samples/1_Utilities/deviceQuery && make\n"
      ],
      "metadata": {
        "id": "B3EUu36vQQVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd cuda-samples/Samples/1_Utilities/deviceQuery && ls\n",
        "!cuda-samples/Samples/1_Utilities/deviceQuery/./deviceQuery"
      ],
      "metadata": {
        "id": "oSYH_oRqQl8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nvcc for Jupyter notebook"
      ],
      "metadata": {
        "id": "3ziDtLTyLArg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "id": "-G6_2BDjK4r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "id": "nYLqxQsBLKKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "int main()\n",
        "{\n",
        "    std::cout << \"Hello World\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "G5TygGBiLMaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "__global__ void kernel( void ){\n",
        "\n",
        "}\n",
        "int main( void ) {\n",
        "    kernel<<<1,1>>>();\n",
        "    printf( \"Hello, World!\\n\" );\n",
        "    return 0;\n",
        "    }"
      ],
      "metadata": {
        "id": "C1BR63BY6yc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "// Adding two number in GPU\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void add(int a, int b, int *c)\n",
        "{\n",
        "    *c = a + b;\n",
        "    }\n",
        "int main( void )\n",
        "{\n",
        "    int c;\n",
        "    int *dev_c;\n",
        "    cudaMalloc( (void**)&dev_c, sizeof(int) );\n",
        "    add<<<1,1>>>( 28, 17, dev_c );\n",
        "    cudaMemcpy( &c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    printf( \"Sum from GPU = %d\\n\", c );\n",
        "    cudaFree( dev_c );\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "e_M4JMPD9dqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#define N 10\n",
        "\n",
        "#include<iostream>\n",
        "using namespace std;\n",
        "__global__ void vector_add(float *out, float *a, float *b, int n) {\n",
        "    for(int i = 0; i < n; i++){\n",
        "      out[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float *a, *b, *out;\n",
        "    float *d_a, *d_b, *d_out;\n",
        "\n",
        "    a   = (float*)malloc(sizeof(float) * N);\n",
        "    b   = (float*)malloc(sizeof(float) * N);\n",
        "    out = (float*)malloc(sizeof(float) * N);\n",
        "    // Initialize array\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f; b[i] = 2.0f;out[i] =0.0f;\n",
        "    }\n",
        "\n",
        "//    // Allocate memory\n",
        "      cudaMalloc((void**)&d_a, sizeof(float) * N);\n",
        "      cudaMemcpy(d_a, a, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "      cudaMalloc((void**)&d_b, sizeof(float) * N);\n",
        "      cudaMemcpy(d_b, b, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "      cudaMalloc((void**)&d_out, sizeof(float) * N);\n",
        "      cudaMemcpy(d_out, out, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "      // Main function\n",
        "      vector_add<<<1,1>>>(d_out, d_a, d_b, N);\n",
        "\n",
        "      cudaMemcpy(out, d_out, sizeof(float) * N, cudaMemcpyDeviceToHost);\n",
        "\n",
        "      for (int idx = 0; idx < N; idx++)\n",
        "      {\n",
        "        std::cout << a[idx] << \" , \";\n",
        "        std::cout << b[idx] << \" , \";\n",
        "        std::cout << out[idx] << \" , \";\n",
        "      }\n",
        "\n",
        "      cudaFree(d_a);\n",
        "      free(a);\n",
        "      cudaFree(d_b);\n",
        "      free(b);\n",
        "      cudaFree(d_out);\n",
        "      free(out);\n",
        "}"
      ],
      "metadata": {
        "id": "Eca28mianaEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "#define N 10\n",
        "\n",
        "#include<iostream>\n",
        "using namespace std;\n",
        "__global__ void vector_add(float *out, float *a, float *b, int n) {\n",
        "    for(int i = 0; i < n; i++){\n",
        "      out[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float *a, *b, *out;\n",
        "    float *d_a, *d_b, *d_out;\n",
        "\n",
        "    a   = (float*)malloc(sizeof(float) * N);\n",
        "    b   = (float*)malloc(sizeof(float) * N);\n",
        "    out = (float*)malloc(sizeof(float) * N);\n",
        "    // Initialize array\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f; b[i] = 2.0f;out[i] =0.0f;\n",
        "    }\n",
        "\n",
        "//    // Allocate memory\n",
        "      cudaMalloc((void**)&d_a, sizeof(float) * N);\n",
        "      cudaMemcpy(d_a, a, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "      cudaMalloc((void**)&d_b, sizeof(float) * N);\n",
        "      cudaMemcpy(d_b, b, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "      cudaMalloc((void**)&d_out, sizeof(float) * N);\n",
        "      cudaMemcpy(d_out, out, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "      // Main function\n",
        "      vector_add<<<1,1>>>(d_out, d_a, d_b, N);\n",
        "\n",
        "      cudaMemcpy(out, d_out, sizeof(float) * N, cudaMemcpyDeviceToHost);\n",
        "\n",
        "      for (int idx = 0; idx < N; idx++)\n",
        "      {\n",
        "        std::cout << a[idx] << \" , \";\n",
        "        std::cout << b[idx] << \" , \";\n",
        "        std::cout << out[idx] << \" , \";\n",
        "      }\n",
        "\n",
        "      cudaFree(d_a);\n",
        "      free(a);\n",
        "      cudaFree(d_b);\n",
        "      free(b);\n",
        "      cudaFree(d_out);\n",
        "      free(out);\n",
        "}"
      ],
      "metadata": {
        "id": "fD_7KI60onMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "/* Hello World cuda program*/\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void myKernel() {\n",
        "    printf(\"GPU: Hello World.\\n\"); // cout doesnot work in device code\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    std::cout << \"CPU : Hello World\";\n",
        "    myKernel<<<1, 1>>>();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "H_uuOAXIL16r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vector_add.cu -o vector_add"
      ],
      "metadata": {
        "id": "O0hShltPos6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./vector_add"
      ],
      "metadata": {
        "id": "xUTdMlyjowd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void myKernel() {\n",
        "    printf(\"GPU: Hello World.\\n\"); // Avoid print statements inside the kernel function\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    std::cout << \"CPU : Hello World\";\n",
        "    myKernel<<<1, 1>>>();\n",
        "    cudaThreadSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "EPPducR3MWXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "__global__ void myKernel(){\n",
        "    printf(\"Hello World.\\n\");\n",
        "  }\n",
        "int main() {\n",
        "    myKernel<<<1, 32>>>();\n",
        "    cudaThreadSynchronize();\n",
        "    return 0;\n",
        "  }"
      ],
      "metadata": {
        "id": "z3uNAZeDNVIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#define N 10\n",
        "\n",
        "__device__ int getID(){\n",
        "    return blockIdx.x*blockDim.x + threadIdx.x;\n",
        "}\n",
        "__global__ void myKernel() {\n",
        "    int a = getID();\n",
        "     printf(\"%d - %d\\n\", threadIdx.x,a);\n",
        "     }\n",
        "int main() {\n",
        "    myKernel<<<N, 1>>>();\n",
        "    cudaThreadSynchronize();\n",
        "    return 0; }"
      ],
      "metadata": {
        "id": "VD2GC8Y5NqGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Typical Cuda program\n",
        "- Load data to CPU memory\n",
        "- Transfer data to GPU memory\n",
        "- Lauch kernels to act on the data\n",
        "- Transfer back data to CPU memory\n",
        "- Proceed with CPU execution"
      ],
      "metadata": {
        "id": "a6TnoEX7OhQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#define N 10\n",
        "__global__ void scaleArr(int *a){\n",
        "      a[threadIdx.x] = threadIdx.x * 10;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int a_hs[N], *a_dev;\n",
        "    int i;\n",
        "    cudaMalloc(&a_dev, N * sizeof(int));\n",
        "\n",
        "    scaleArr<<<1, N>>>(a_dev);\n",
        "    cudaMemcpy(a_hs, a_dev, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    for (i = 0; i < N; ++i)\n",
        "      printf(\"%d\\n\", a_hs[i]);\n",
        "    return 0;\n",
        "  }"
      ],
      "metadata": {
        "id": "_0V8dRyQOJGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the Unique ID of different threads?\n",
        "\n",
        "https://github.com/tpn/pdfs/blob/master/CUDA%20Thread-Indexing%20Cheatsheet.pdf"
      ],
      "metadata": {
        "id": "8fHbiDqCRijR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3KlPEFiYoeVB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}